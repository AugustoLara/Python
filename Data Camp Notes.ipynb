{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data camp notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-830581a27b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Call count_entries(): result_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mresult_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tweets.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Print result_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-830581a27b90>\u001b[0m in \u001b[0;36mcount_entries\u001b[0;34m(csv_file, c_size, colname)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Iterate over the file chunk by chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Iterate over the column in DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Iterating on a csv file on chunk size\n",
    "\n",
    "# Define count_entries()\n",
    "def count_entries(csv_file, c_size, colname):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "\n",
    "    # Iterate over the file chunk by chunk\n",
    "    for chunk in pd.read_csv(csv_file,chunksize=c_size):\n",
    "\n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in chunk[colname]:\n",
    "            if entry in counts_dict.keys():\n",
    "                counts_dict[entry] += 1\n",
    "            else:\n",
    "                counts_dict[entry] = 1\n",
    "\n",
    "    # Return counts_dict\n",
    "    return counts_dict\n",
    "\n",
    "# Call count_entries(): result_counts\n",
    "result_counts = count_entries('tweets.csv', 10,'lang')\n",
    "\n",
    "# Print result_counts\n",
    "print(result_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "#Creating a Matrix with a nested comprehension\n",
    "\n",
    "# Create a 5 x 5 matrix using a list of lists: matrix\n",
    "matrix = [[col for col in range(0,5)] for row in range(0,5)]\n",
    "\n",
    "# Print the matrix\n",
    "for row in matrix:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-fb8a61daad28>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-fb8a61daad28>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    ---\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#IF and IF-ELSE List comprehensions\n",
    "#IF\n",
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member for member in fellowship if len(member) >= 7]\n",
    "type(new_fellowship)\n",
    "# Print the new list\n",
    "print(new_fellowship)\n",
    "\n",
    "---\n",
    "#IF-ELSE\n",
    "for member in fellowship "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "# Define plot_pop()\n",
    "def plot_pop(filename, country_code):\n",
    "\n",
    "    # Initialize reader object: urb_pop_reader\n",
    "    urb_pop_reader = pd.read_csv(filename, chunksize=1000)\n",
    "\n",
    "    # Initialize empty DataFrame: data\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over each DataFrame chunk\n",
    "    for df_urb_pop in urb_pop_reader:\n",
    "        # Check out specific country: df_pop_ceb\n",
    "        df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == country_code]\n",
    "\n",
    "        # Zip DataFrame columns of interest: pops\n",
    "        pops = zip(df_pop_ceb['Total Population'],\n",
    "                    df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "        # Turn zip object into list: pops_list\n",
    "        pops_list = list(pops)\n",
    "\n",
    "        # Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "        df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1]) for tup in pops_list]\n",
    "    \n",
    "        # Append DataFrame chunk to data: data\n",
    "        data = data.append(df_pop_ceb)\n",
    "\n",
    "    # Plot urban population data\n",
    "    data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "    plt.show()\n",
    "\n",
    "# Set the filename: fn\n",
    "fn = 'ind_pop_data.csv'\n",
    "\n",
    "# Call plot_pop for country code 'CEB'\n",
    "plot_pop(fn,'CEB')\n",
    "\n",
    "# Call plot_pop for country code 'ARB'\n",
    "plot_pop(fn,'ARB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = pd.read_csv('Country.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShortName</th>\n",
       "      <th>TableName</th>\n",
       "      <th>LongName</th>\n",
       "      <th>Alpha2Code</th>\n",
       "      <th>CurrencyUnit</th>\n",
       "      <th>SpecialNotes</th>\n",
       "      <th>Region</th>\n",
       "      <th>IncomeGroup</th>\n",
       "      <th>Wb2Code</th>\n",
       "      <th>NationalAccountsBaseYear</th>\n",
       "      <th>...</th>\n",
       "      <th>GovernmentAccountingConcept</th>\n",
       "      <th>ImfDataDisseminationStandard</th>\n",
       "      <th>LatestPopulationCensus</th>\n",
       "      <th>LatestHouseholdSurvey</th>\n",
       "      <th>SourceOfMostRecentIncomeAndExpenditureData</th>\n",
       "      <th>VitalRegistrationComplete</th>\n",
       "      <th>LatestAgriculturalCensus</th>\n",
       "      <th>LatestIndustrialData</th>\n",
       "      <th>LatestTradeData</th>\n",
       "      <th>LatestWaterWithdrawalData</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountryCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AFG</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Islamic State of Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>Afghan afghani</td>\n",
       "      <td>Fiscal year end: March 20; reporting period fo...</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Low income</td>\n",
       "      <td>AF</td>\n",
       "      <td>2002/03</td>\n",
       "      <td>...</td>\n",
       "      <td>Consolidated central government</td>\n",
       "      <td>General Data Dissemination System (GDDS)</td>\n",
       "      <td>1979</td>\n",
       "      <td>Multiple Indicator Cluster Survey (MICS), 2010/11</td>\n",
       "      <td>Integrated household survey (IHS), 2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013/14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Republic of Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>Albanian lek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>Upper middle income</td>\n",
       "      <td>AL</td>\n",
       "      <td>Original chained constant price data are resca...</td>\n",
       "      <td>...</td>\n",
       "      <td>Budgetary central government</td>\n",
       "      <td>General Data Dissemination System (GDDS)</td>\n",
       "      <td>2011</td>\n",
       "      <td>Demographic and Health Survey (DHS), 2008/09</td>\n",
       "      <td>Living Standards Measurement Study Survey (LSM...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2012</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DZA</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>People's Democratic Republic of Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>Algerian dinar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "      <td>Upper middle income</td>\n",
       "      <td>DZ</td>\n",
       "      <td>1980</td>\n",
       "      <td>...</td>\n",
       "      <td>Budgetary central government</td>\n",
       "      <td>General Data Dissemination System (GDDS)</td>\n",
       "      <td>2008</td>\n",
       "      <td>Multiple Indicator Cluster Survey (MICS), 2012</td>\n",
       "      <td>Integrated household survey (IHS), 1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASM</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "      <td>U.S. dollar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Upper middle income</td>\n",
       "      <td>AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADO</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Principality of Andorra</td>\n",
       "      <td>AD</td>\n",
       "      <td>Euro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>High income: nonOECD</td>\n",
       "      <td>AD</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011. Population data compiled from administra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ShortName       TableName  \\\n",
       "CountryCode                                   \n",
       "AFG             Afghanistan     Afghanistan   \n",
       "ALB                 Albania         Albania   \n",
       "DZA                 Algeria         Algeria   \n",
       "ASM          American Samoa  American Samoa   \n",
       "ADO                 Andorra         Andorra   \n",
       "\n",
       "                                            LongName Alpha2Code  \\\n",
       "CountryCode                                                       \n",
       "AFG                     Islamic State of Afghanistan         AF   \n",
       "ALB                              Republic of Albania         AL   \n",
       "DZA          People's Democratic Republic of Algeria         DZ   \n",
       "ASM                                   American Samoa         AS   \n",
       "ADO                          Principality of Andorra         AD   \n",
       "\n",
       "               CurrencyUnit  \\\n",
       "CountryCode                   \n",
       "AFG          Afghan afghani   \n",
       "ALB            Albanian lek   \n",
       "DZA          Algerian dinar   \n",
       "ASM             U.S. dollar   \n",
       "ADO                    Euro   \n",
       "\n",
       "                                                  SpecialNotes  \\\n",
       "CountryCode                                                      \n",
       "AFG          Fiscal year end: March 20; reporting period fo...   \n",
       "ALB                                                        NaN   \n",
       "DZA                                                        NaN   \n",
       "ASM                                                        NaN   \n",
       "ADO                                                        NaN   \n",
       "\n",
       "                                 Region           IncomeGroup Wb2Code  \\\n",
       "CountryCode                                                             \n",
       "AFG                          South Asia            Low income      AF   \n",
       "ALB               Europe & Central Asia   Upper middle income      AL   \n",
       "DZA          Middle East & North Africa   Upper middle income      DZ   \n",
       "ASM                 East Asia & Pacific   Upper middle income      AS   \n",
       "ADO               Europe & Central Asia  High income: nonOECD      AD   \n",
       "\n",
       "                                      NationalAccountsBaseYear  \\\n",
       "CountryCode                                                      \n",
       "AFG                                                    2002/03   \n",
       "ALB          Original chained constant price data are resca...   \n",
       "DZA                                                       1980   \n",
       "ASM                                                        NaN   \n",
       "ADO                                                       2000   \n",
       "\n",
       "                       ...                 GovernmentAccountingConcept  \\\n",
       "CountryCode            ...                                               \n",
       "AFG                    ...             Consolidated central government   \n",
       "ALB                    ...                Budgetary central government   \n",
       "DZA                    ...                Budgetary central government   \n",
       "ASM                    ...                                         NaN   \n",
       "ADO                    ...                                         NaN   \n",
       "\n",
       "                         ImfDataDisseminationStandard  \\\n",
       "CountryCode                                             \n",
       "AFG          General Data Dissemination System (GDDS)   \n",
       "ALB          General Data Dissemination System (GDDS)   \n",
       "DZA          General Data Dissemination System (GDDS)   \n",
       "ASM                                               NaN   \n",
       "ADO                                               NaN   \n",
       "\n",
       "                                        LatestPopulationCensus  \\\n",
       "CountryCode                                                      \n",
       "AFG                                                       1979   \n",
       "ALB                                                       2011   \n",
       "DZA                                                       2008   \n",
       "ASM                                                       2010   \n",
       "ADO          2011. Population data compiled from administra...   \n",
       "\n",
       "                                         LatestHouseholdSurvey  \\\n",
       "CountryCode                                                      \n",
       "AFG          Multiple Indicator Cluster Survey (MICS), 2010/11   \n",
       "ALB               Demographic and Health Survey (DHS), 2008/09   \n",
       "DZA             Multiple Indicator Cluster Survey (MICS), 2012   \n",
       "ASM                                                        NaN   \n",
       "ADO                                                        NaN   \n",
       "\n",
       "                    SourceOfMostRecentIncomeAndExpenditureData  \\\n",
       "CountryCode                                                      \n",
       "AFG                    Integrated household survey (IHS), 2008   \n",
       "ALB          Living Standards Measurement Study Survey (LSM...   \n",
       "DZA                    Integrated household survey (IHS), 1995   \n",
       "ASM                                                        NaN   \n",
       "ADO                                                        NaN   \n",
       "\n",
       "            VitalRegistrationComplete LatestAgriculturalCensus  \\\n",
       "CountryCode                                                      \n",
       "AFG                               NaN                  2013/14   \n",
       "ALB                               Yes                     2012   \n",
       "DZA                               NaN                      NaN   \n",
       "ASM                               Yes                     2007   \n",
       "ADO                               Yes                      NaN   \n",
       "\n",
       "            LatestIndustrialData LatestTradeData LatestWaterWithdrawalData  \n",
       "CountryCode                                                                 \n",
       "AFG                          NaN          2013.0                    2000.0  \n",
       "ALB                       2011.0          2013.0                    2006.0  \n",
       "DZA                       2010.0          2013.0                    2001.0  \n",
       "ASM                          NaN             NaN                       NaN  \n",
       "ADO                          NaN          2006.0                       NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data in Python 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading text using numpy arrays\n",
    "\n",
    "import numpy as np\n",
    "# Assign the filename: file\n",
    "file = 'digits_header.txt'\n",
    "\n",
    "# Load the data: data\n",
    "# Delimiter can be set to ',' or '\\t' for tab\n",
    "# skiprows=1 to skip headers and avoid type conversions or error\n",
    "# usecols takes a list of the columns to be imported\n",
    "data = np.loadtxt(____, delimiter=____, skiprows=____, usecols=____)\n",
    "\n",
    "# Importing data with multiple data types\n",
    "# names = True means there are headers\n",
    "# Python will create 1D arrays to handle the one data type rule\n",
    "data = np.genfromtxt('titanic.csv', delimiter=',', names=True,dtype=None)\n",
    "\n",
    "# np.recfromcvs() is similar and saves time thanks to the\n",
    "#... defaults delimiter=',' and names=True in addition to dtype=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pandas is python's response to R and can handle observations and variables well\n",
    "# sep is the equivalent of delimiter\n",
    "# comment specifies how comments start in the file\n",
    "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! ls\n",
    "\n",
    "# The os package can also be used\n",
    "\n",
    "import os\n",
    "wd = os.getcwd()\n",
    "os.listdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational databases using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQL Alchemy allows SQL queries, combined with pandas they can be transformed in dataframes\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# The connectin can be opened 'with' as shown below or con = engine.connect()\n",
    "with engine.connect() as con:\n",
    "    # Perform query: rs\n",
    "    rs = con.execute('SELECT LastName, Title from Employee')\n",
    "    # Save results of the query to DataFrame: df\n",
    "    df = pd.DataFrame(rs.fetchmany(size=5))\n",
    "    # Set keys to columns in the df\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())\n",
    "\n",
    "# A shorter way to get the same results is to use athe read_sql_query method in pandas\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Execute query and store records in DataFrame: df\n",
    "df = pd.read_sql_query('SELECT * FROM Album', engine)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data in Python 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat files and non-flat files from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flat files\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Read file into a DataFrame: df\n",
    "df = pd.read_csv(url,sep=';')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Non-flat files (Excel)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'http://s3.amazonaws.com/assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "xl = pd.read_excel(url,sheetname=None)\n",
    "\n",
    "# Print the sheetnames to the shell\n",
    "print(xl.keys())\n",
    "\n",
    "# Print the head of the first sheet (using its name, NOT its index)\n",
    "print(xl['1700'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "\n",
      "\n",
      "Guido's Personal Home Page\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Guido van Rossum - Personal Home Page\n",
      "\"Gawky and proud of it.\"\n",
      "Who\n",
      "I Am\n",
      "Read\n",
      "my \"King's\n",
      "Day Speech\" for some inspiration.\n",
      "\n",
      "I am the author of the Python\n",
      "programming language.  See also my resume\n",
      "and my publications list, a brief bio, assorted writings, presentations and interviews (all about Python), some\n",
      "pictures of me,\n",
      "my new blog, and\n",
      "my old\n",
      "blog on Artima.com.  I am\n",
      "@gvanrossum on Twitter.  I\n",
      "also have\n",
      "a G+\n",
      "profile.\n",
      "\n",
      "In January 2013 I joined\n",
      "Dropbox.  I work on various Dropbox\n",
      "products and have 50% for my Python work, no strings attached.\n",
      "Previously, I have worked for Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my resume.)  I created Python while at CWI.\n",
      "\n",
      "How to Reach Me\n",
      "You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but if you ask\n",
      "me a question about using Python, it's likely that I won't have time\n",
      "to answer it, and will instead refer you to\n",
      "help (at) python.org,\n",
      "comp.lang.python or\n",
      "StackOverflow.  If you need to\n",
      "talk to me on the phone or send me something by snail mail, send me an\n",
      "email and I'll gladly email you instructions on how to reach me.\n",
      "\n",
      "My Name\n",
      "My name often poses difficulties for Americans.\n",
      "\n",
      "Pronunciation: in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "sound clip.)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "\n",
      "Spelling: my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "\n",
      "Alphabetization: in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "\n",
      "\n",
      "More Hyperlinks\n",
      "\n",
      "Here's a collection of essays relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "I own the official \n",
      "Python license.\n",
      "\n",
      "The Audio File Formats FAQ\n",
      "I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at http://www.cnpbagwell.com/audio-faq.  And here is a link to\n",
      "SOX, to which I contributed\n",
      "some early code.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "\n",
      "\n",
      "\n",
      "pics.html\n",
      "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
      "http://metalab.unc.edu/Dave/Dr-Fun/df200004/df20000406.jpg\n",
      "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
      "http://www.python.org\n",
      "Resume.html\n",
      "Publications.html\n",
      "bio.html\n",
      "http://legacy.python.org/doc/essays/\n",
      "http://legacy.python.org/doc/essays/ppt/\n",
      "interviews.html\n",
      "pics.html\n",
      "http://neopythonic.blogspot.com\n",
      "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
      "https://twitter.com/gvanrossum\n",
      "https://plus.google.com/u/0/115212051037621986145/posts\n",
      "http://www.dropbox.com\n",
      "Resume.html\n",
      "http://groups.google.com/groups?q=comp.lang.python\n",
      "http://stackoverflow.com\n",
      "guido.au\n",
      "http://legacy.python.org/doc/essays/\n",
      "images/license.jpg\n",
      "http://www.cnpbagwell.com/audio-faq\n",
      "http://sox.sourceforge.net/\n",
      "images/internetdog.gif\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Extracting Title. Get the title of Guido's webpage: guido_title\n",
    "guido_title = soup.title\n",
    "\n",
    "# Print the title of Guido's webpage to the shell\n",
    "print(guido_title)\n",
    "\n",
    "# Extracting text. Get Guido's text: guido_text\n",
    "guido_text = soup.text\n",
    "\n",
    "# Print Guido's text to the shell\n",
    "print(guido_text)\n",
    "\n",
    "# Extracting hyperlinks. Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "a_tags\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import JSONs into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><b>Pizza</b> is a traditional Italian dish consisting of a yeasted flatbread typically topped with tomato sauce and cheese and baked in an oven. It is commonly topped with a selection of meats, vegetables and condiments.</p>\n",
      "<p>The term <i>pizza</i> was first recorded in the 10th century, in a Latin manuscript from Gaeta in Southern Lazio on the border with Campania. Modern pizza was invented in Naples, Campania, Southern Italy, and the dish and its variants have since become popular and common in many areas of the world. In 2009, upon Italy's request, Neapolitan pizza was safeguarded in the European Union as a Traditional Speciality Guaranteed dish. <i>Associazione Verace Pizza Napoletana</i> (True Neapolitan Pizza Association), a non-profit organization founded in 1984 with headquarters in Naples, aims to \"promote and protect... the true Neapolitan pizza\".</p>\n",
      "<p>Pizza is one of the most popular food in the world and common fast food item in Europe and North America. Many separate or chain restaurant, cafes and fast foods offers pizza. Also pizza is main dish in special pizzerias and even in worldwide chain nets of pizzerias. Pizza delivery offers by many cooker preparators and is very popular.</p>\n",
      "<p>Pizza is sold fresh or frozen, either whole or in portions. Various types of ovens are used to cook them and many varieties exist. Several similar dishes are prepared from ingredients commonly used in pizza preparation, such as calzone and stromboli. Pizza is usually eating by hands after dividing in slices of large pizza or small pizzetta as a whole. The frozen pizza for microwave ovens is very popular since the end of 20th century.</p>\n",
      "{'batchcomplete': '', 'query': {'normalized': [{'from': 'pizza', 'to': 'Pizza'}], 'pages': {'24768': {'pageid': 24768, 'ns': 0, 'title': 'Pizza', 'extract': '<p><b>Pizza</b> is a traditional Italian dish consisting of a yeasted flatbread typically topped with tomato sauce and cheese and baked in an oven. It is commonly topped with a selection of meats, vegetables and condiments.</p>\\n<p>The term <i>pizza</i> was first recorded in the 10th century, in a Latin manuscript from Gaeta in Southern Lazio on the border with Campania. Modern pizza was invented in Naples, Campania, Southern Italy, and the dish and its variants have since become popular and common in many areas of the world. In 2009, upon Italy\\'s request, Neapolitan pizza was safeguarded in the European Union as a Traditional Speciality Guaranteed dish. <i>Associazione Verace Pizza Napoletana</i> (True Neapolitan Pizza Association), a non-profit organization founded in 1984 with headquarters in Naples, aims to \"promote and protect... the true Neapolitan pizza\".</p>\\n<p>Pizza is one of the most popular food in the world and common fast food item in Europe and North America. Many separate or chain restaurant, cafes and fast foods offers pizza. Also pizza is main dish in special pizzerias and even in worldwide chain nets of pizzerias. Pizza delivery offers by many cooker preparators and is very popular.</p>\\n<p>Pizza is sold fresh or frozen, either whole or in portions. Various types of ovens are used to cook them and many varieties exist. Several similar dishes are prepared from ingredients commonly used in pizza preparation, such as calzone and stromboli. Pizza is usually eating by hands after dividing in slices of large pizza or small pizzetta as a whole. The frozen pizza for microwave ovens is very popular since the end of 20th century.</p>'}}}}\n"
     ]
    }
   ],
   "source": [
    "# The example below shows how an Python can import json from wikipedia's API, and navigate json's within jsons as\n",
    "# dictionaries inside dictionaries. \n",
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print the Wikipedia page extract\n",
    "pizza_extract = json_data['query']['pages']['24768']['extract']\n",
    "print(pizza_extract)\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define listener\n",
    "import tweepy\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(\"tweets.txt\", \"w\")\n",
    "\n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write( json.dumps(tweet) + '\\n' )\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 10000:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Authentication, retrival, storage and reading of data\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Store OAuth authentication credentials in relevant variables\n",
    "access_token = \"40240876-cBkR2EJeAM8R0E1WVCQRlhMtYAg01Bdj3W3RGI4tS\"\n",
    "access_token_secret = \"HUTJCioetHLGrk9fTdU5FFg9gMmoK8Uv9znpX8MEV9oBJ\"\n",
    "consumer_key = \"BTK23tH4NsxDppPi177T3qOJr\"\n",
    "consumer_secret = \"Sh5xC6Dvizwp7N7AyEyP4gOpPSwemx9zrAwJSo4X1EGrIXmChV\"\n",
    "\n",
    "# Pass OAuth details to tweepy's OAuth handler\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "# Initialize Stream listener\n",
    "l = MyStreamListener()\n",
    "\n",
    "# Create you Stream object with authentication\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "stream.filter(track=['clinton', 'trump', 'sanders', 'cruz'])\n",
    "\n",
    "\n",
    "# String of path to file: tweets_data_path\n",
    "tweets_data_path = 'tweets.txt'\n",
    "\n",
    "# Initialize empty list to store tweets: tweets_data\n",
    "tweets_data = []\n",
    "\n",
    "# Open connection to file\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text lang\n",
      "0  RT @gettinnoticedmo: I am not in anyway insinu...   en\n",
      "1  What? Why would a judge do this? #Manafort #Tr...   en\n",
      "2  RT @AynRandPaulRyan: \"Mr. Trump, can we ask yo...   en\n",
      "3  RT @funder: DOJ now says early release of FBI ...   en\n",
      "4  @realDonaldTrump Way to go President Trump.   ...   en\n"
     ]
    }
   ],
   "source": [
    "# Build DataFrame of tweet texts and languages\n",
    "df = pd.DataFrame(tweets_data, columns=['text','lang'])\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize word counter\n",
    "import re\n",
    "\n",
    "def word_in_text(word, tweet):\n",
    "    word = word.lower()\n",
    "    text = tweet.lower()\n",
    "    match = re.search(word, tweet)\n",
    "\n",
    "    if match:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize list to store tweet counts\n",
    "[clinton, trump, sanders, cruz] = [0, 0, 0, 0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in df.iterrows():\n",
    "    clinton += word_in_text('clinton', row['text'])\n",
    "    trump += word_in_text('trump', row['text'])\n",
    "    sanders += word_in_text('sanders', row['text'])\n",
    "    cruz += word_in_text('cruz', row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFJCAYAAACyzKU+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d4f6f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing data\n",
    "\n",
    "# Import packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Create a list of labels:cd\n",
    "cd = ['clinton', 'trump', 'sanders', 'cruz']\n",
    "\n",
    "# Plot histogram\n",
    "ax = sns.barplot(cd, [clinton, trump, sanders, cruz])\n",
    "ax.set(ylabel=\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cleaning data in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=42)\n",
    "\n",
    "# Create the regressor: reg_all\n",
    "reg_all = LinearRegression()\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "reg_all.fit(X_train,y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = reg_all.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(reg_all.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation - create 5 folds, we use 4 folds and test vs 1 (5 times) and calculate R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a linear regression object: reg\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Compute 5-fold cross-validation scores: cv_scores\n",
    "cv_scores = cross_val_score(reg, X, y, cv=5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "print(cv_scores)\n",
    "\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
